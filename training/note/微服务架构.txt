# 微服务架构

## 服务注册与发现

服务注册与发现演进
第一阶段: 直接IP+端口访问  特点: 客户端保存着IP端口信息, 需要提前配置好
    缺点: IP地址会变, 如果实例很多, 配置难以维护
第二阶段: 域名解析  特点: 客户端保存服务的endpoint, 客户端也可以缓存dns解析的结果
    缺点: 客户端不缓存则多一次调用, 缓存则存在不一致性
第三阶段: 分布式协调-注册中心阶段 特点: 服务端发起注册, 客户端向注册中心询问, 注册中心维持住两端
    缺点: 基本没有显著的缺点, 不过在大规模集群下, 注册中心容易称为瓶颈, 网络中比较多探活流量

总结
服务注册中心模式, 核心是依赖于一个第三方组件
基本模型
1. 服务启动成功之后主动注册
2. 服务端和注册中心保持心跳
3. 客户端启动的时候要主动订阅对应服务的数据
4. 注册中心要通知客户端变更
理解难点
1. 运行过程中, 客户端连不上注册中心怎么办?
2. 运行过程中, 客户端拿到了注册数据, 但是连不上对应的服务端怎么办?
3. 注册过程中, 注册中心没有收到服务端心跳怎么办?
4. 注册中心崩溃了, 客户端和服务端怎么办?

gRPC服务注册与发现
grpc服务注册与发现的核心在resolver包, 核心接口有
1) Target: 被解析的目标, 是对服务的抽象
2) Builder: Builder模式, 用于构建一个Resolver
Resolver: 负责服务发现
gRPC服务注册与发现的重要实现就是基于DNS的实现: dnsResolver和dnsBuilder
其中核心方法时watcher, 它的整体逻辑可以看成是一个拉模型, 即轮询DBS服务器来刷新本地可用的服务器列表
服务发现里面的两个基本模型
1) 推模型: 注册中心主动推送变更给客户端
2) 拉模型: 客户端轮询注册中心. 这种模型其实不好管, 因为用户(或者中间件研发者)要考虑多久刷新一次, 快了浪费资源, 慢了又是数据不一致

Kratos服务注册与发现
Kratos本身是建立在gRPC上的, 但是它又有自己的服务注册与发现接口
1) Register: 对应于服务注册部分
2) Discovery: 对应于服务发现部分
3) Watcher: 监听服务变更部分

服务注册与发现总结
注册一般就是两种维度
1) 接口维度: 一个接口注册一次, 服务发现的时候也是使用接口来查找
2) 应用维度: 一个应用注册一次, 一个应用有很多服务. 这些服务共享一些基本信息, 同时不同服务还有独特的信息
两种注册维度又是不是很明显, 并且两种都有人用: 接口维度可控性更强, 粒度更细, 但是写入的数据, 心跳等开销更大; 应用维度粒度更细, 但是数据更少
注册数据则总体分为两类
定位信息: 例如 ip+端口
其他: 这主要取决于微服务框架的具体功能, 例如在Dubbo-go里面可以写入标签信息, 分组信息
核心接口 ①服务注册--针对服务端 ②服务发现--针对客户端 ③监听变更--针对客户端

## 自定义服务注册与发现

目标: 使用etcd来实现一个服务注册中心, 在gRPC内部接入我们自己的服务注册与发现
gRPC服务注册与发现机制
1. gRPC本身没有提供服务注册接口, 也就是服务注册本身, 是我们自己管的
2. gRPC只提供了服务解析的接口, 也就是Resolver和对应的Builder两个接口

代码演示 micro_v1
v0: 完成服务注册v0代码
v1: ResolverNow方法和watch方法单元测试
v2: 完成etcd实现服务注册的功能, 完成e2e测试代码

mock代码生成
mockgen -package mocks -destination mocks/kv.mock.go -source C:\Users\Administrator\go\pkg\mod\go.etcd.io\etcd\client\v3@v3.5.4\kv.go
mockgen -package mocks -destination mocks/watch.mock.go -source C:\Users\Administrator\go\pkg\mod\go.etcd.io\etcd\client\v3@v3.5.4\watch.go

gRPC服务发现流程
1. 用户在初始化gRPC的时候指定grpc.WithResolver选项, 传入自定义的Resolver
2. 在Dial调用的时候传入服务标识符, 一般形式是scheme:///service-name, scheme代表的是如何通信的. 大多数时候, 它就是代表我们注册中心
3. gRPC会根据scheme来找到我们注册的Resolver, 我们在Resolver里面更新可用的连接

服务崩溃之后, 客户端多久才能知道
取决于服务端和注册中心的交互方式:
    如果是注册中心主动发起心跳, 那么就主要取决于心跳的间隔, 以及多少次心跳失败才会判定服务器崩溃
    如果是服务端主动续约而没有心跳, 那么就取决于租约长短, 以及续约的重试机制
心跳是一个很复杂的事情:
    心跳频繁, 那么挤占正常请求的资源, 但是容易发现服务端崩溃
    心跳不频繁, 那么注册中心很难发现节点崩溃
心跳失败之后的判定
    一次心跳失败判定节点失活: 过于严苛, 部分时候网络抖动就会引起误判
    连续多次心跳判定节点失活: 连续多次失败才判定一个节点崩溃, 未能及时发现节点崩溃

客户端和注册中心连不上怎么办?
可能 ①网络问题 ②注册中心崩溃
策略
    客户端直接停止服务, 直到恢复和注册中心的连接
    客户端继续服务, 并且尝试重新脸上注册中心, 这段时间内使用的都是本地缓存数据. 再过一段时间连不上之后, 再停止服务

利用健康检查来决定注册时机
微服务框架里面有一种做法, 就是微服务框架在启动服务之后, 会给服务发一个健康检查或者心跳, 如果收到了成功的响应, 那么就认为服务启动成功了
只有在这个时候, 微服务框架才会注册数据. 实际上这个东西没什么用, 因为你健康检查通过了, 只能认为你端口启动成功了, 你微服务在业务层面上启动了没有, 还是不知道的.

容器内部IP问题
注意到, 我们的etcd实现里面, 我们使用的是IP+端口来识别, 问题就在于如果微服务运行于容器内部, 例如Docker, 那么拿到的IP其实永远都是localhost
而客户端运行在另外一个容器内, 使用localhost是无法连接上服务端的
在这种情况下, 微服务只能选择:
    使用容器专属的注册与发现方式
    容器启动的时候使用宿主机的网络, 而不是创建一个虚拟网络
    容器启动的时候想办法把宿主机的IP作为环境变量注入进去

中间件选型
体量小的时候, 10000个服务实例内, 只要是主流的就都没问题: zookeeper, nacos, etcd
在体量大之后要考虑
    集群模型: 对等模型和主从模型
    CAP: 大集群偏向AP, 小集群偏向CP. AP存在客户端缓存的数据过期问题, CP存在注册中心不可用问题

## 负载均衡

注册中心解决的是有哪些可用服务实例, 负载均衡解决的是这么多可用服务实例, 我该把请求发给谁?
从理论上来说, 我们希望将请求发给那个能最快返回响应给我的实例

主流的负载均衡算法
完全不实时计算负载的算法: 轮询, 加权轮询, 随机, 加权随机, 哈希, 一致性哈希
尝试实时计算负载的算法: 最快响应时间, 最少连接数, 最少请求数算法

代码演示 micro_v2
v0: 负载均衡实现轮询算法
v1: 负载均衡实现加权轮询算法
v2: 负载均衡的最少活跃数算法实现 - 没有测试

总结
要不要考虑服务器处理能力? 轮询, 随机, 哈希, 最小连接数, 最少活跃数都没考虑
选择什么指标来表达服务器当前负载?
    随机, 轮询, 哈希 什么都没选, 依赖于统计; 连接数, 请求数, 响应时间, 错误数 这些你可以随便选几个指标, 然后设计自己的负载均衡算法
是不是所有的请求所需资源都是一样的? 显然不是
    大商家品类极多, 大买家订单极多; 不考虑请求消耗资源的负载均衡, 容易出现偶发的打爆某一台实例的情况

微服务框架的局限性 http://mc.xchch.top:6670/download/tech/2211/负载均衡选择-微服务框架局限性.png
客户端选择服务端作为服务提供者时, 是缺乏全局信息的, 那么为什么他们运作的还是很好呢?
因为请求数量多了, 慢慢就会收敛到一种比较均匀的状态

设计自己的负载均衡算法
核心是根据自己的服务特征来选取一些指标, 来表达实例的负载. 指标可以是服务指标(错误率等)和硬件指标(CPU、IO、网络负载等)

## 路由策略

负载均衡时的业务需求, 称为路由策略. 业务需求可以有
* 在A/B测试中, A请求只能发过去A节点
* 在全链路压测中, 压测流量只能发过去测试节点上
* 在VIP服务中, VIP的请求要发到更加高端的机器上
* 在联调或者DEBUG的时候, 请求只能发送到一个特定的机器上

代码演示 micro_v3
v0: micro_v2的v1版本代码
v1: 增加分组的功能
v2: 增加广播的功能

过滤功能对负载均衡算法的影响
首先从实现的角度来说, 大部分负载均衡算法都受到了影响, 包括随机、轮询, 以及对应的加权版本
过滤功能使用不当可能会造成负载均衡算法几乎失效
    过滤条件太苛刻以至于满足条件的实例几乎没有
    每次请求过滤之后的节点都不同, 那么可能导致所有的请求都发过去了少部分实例

自定义路由策略
路由是一个非常强业务相关的特性, 即大多数时候我们是根据业务规则来设计路由的, 但是实现和前面我们提到的分组是类似的
设计一个路由可以从以下几个方向考虑
1. 资源隔离角度: 例如VIP用户和普通用户隔离, 付费用户和免费用户隔离
2. 测试: 可以为测试设计专属的路由, 例如在全链路压测中
3. 动态分组: 例如在运行时刻根据节点状况打不同的标签

## 集群抽象 - Cluster

集群抽象我们在调用远程服务的时候, 尝试解决
* failover: 即引入重试功能, 但是重试的时候会换一个新节点
* failfast: 立即失败, 不许需要重试
* 广播: 将请求发送到所有的节点上
* 组播: 组播和分组功能不一样, 组播是指将请求发送到一组节点上, 而不是只发送到单一一个节点上

cluster、路由和负载均衡的关系
本质上, 它们都回答同一个问题: 我要把请求发给谁?
一般来说, cluster是不需要考虑负载均衡的 -- 无论是组播还是广播, 都是发给多个节点
但是cluster中的组播, 可以理解为广播+路由, 因为路由的本质就是筛选出节点

## 可用性

可用性在微服务框架里面是和服务治理最密切相关的主题了
包含熔断 限流 降级 重试 超时控制

熔断, 限流, 降级 并没有本质区别, 都可以归属到故障处理的范畴里面
第一阶段 故障检测: 使用一些特定的算法, 判定服务是否处于不健康状态
第二阶段 故障处理
    限流: 一段时间内只允许特定数量的请求被处理
    熔断: 全部请求都会被拒绝
    降级: 全部请求都会执行一段更加简单的逻辑
第三阶段 故障恢复: 即如果服务被判定为处于异常状态之后, 什么时候再恢复过来

故障检测算法, 分为两类, 对于绝大多数应用来说, 静态类型算法就足够了
静态类型的算法: 令牌桶, 漏桶, 固定窗口和滑动窗口都属于这一类
动态类型的算法: 根据错误率, 根据响应时间, 或者典型的BBR算法

代码演示 micro_v4
v0: micro_v2的v1版本代码
v1: 令牌桶算法
v2: 漏桶算法&固定窗口算法&滑动窗口算法

漏桶算法要点
1. 请求过来先排队
2. 每隔一段时间, 放过去一个请求
3. 请求排队直到通过, 或者超时

令牌桶算法要点
1. 有一个人按照一定的速率发令牌
2. 令牌会被放到一个桶中, 这个桶只能放一个令牌
3. 每一个请求从桶里拿一个令牌
4. 拿到令牌的请求就会被处理
5. 没有拿到令牌的请求就会 ①直接拒绝 ②阻塞直到拿到令牌或者超时

客户端限流与服务端限流
前面的限流方式都是服务端限流 -- 利用的是gRPC的服务端拦截器. 从理论上来说, 还可以考虑客户端限流
客户端限流用的很少, 主要是因为不同客户端上单独限流了, 结果合在一起超过了服务器处理能力

单机限流与集群限流
前面的限流方式都是单机限流 -- 在微服务框架下我们还可以考虑对集群进行限流
集群限流特征: ①非常接近网关限流 ②集群限流主要依赖于在不同的实例之间同步阈值, 当前请求数, 目前使用redis的比较多

限流对象, 即针对什么限流, 除了前面的单机限流和集群限流, 还有 接口维度限流、方法维度限流、业务相关限流
业务相关限流 ①针对用户限流 ②针对IP限流 常见的针对登录请求, 同一个Ip不能频繁登录
业务相关一般会针对安全, 业务价值, 大体上逻辑就是牺牲不重要的来保护重要的
限流也就可以考虑跨服务限流, 即如果服务很重要, 那么将不重要的服务流量摘掉, 或者丢弃一部分, 腾出资源来保护核心服务

拒绝策略
在我们的课堂里面, 目前所有的限流都是默认返回了错误, 在实际中我们可以考虑
* 标记一下这个请求时限流请求, 后续业务走简易路径: 例如结合我们前面的缓存模式, 这种被标记的请求, 我们在缓存未命中的时候直接返回,
    而不会去数据库里面加载
* 直接返回一个固定的响应: 和上一种措施比起来, 这一种直接在拦截器里面就返回了
* 缓存请求: 前面我们的令牌桶和漏铜阻塞住了, 在某种程度上也可以看做是缓存, 这里面的缓存是指我们将请求丢过去一个数据库或者Redis之类的地方存好,
    后面再取出来重做
* 转为异步模式: 拦截器将请求标记为限流请求, 那么后面的业务就会直接返回一个类似202的响应, 即请求已经接收. 后续再由一个调度器重新调度它
    来真正执行. 和前者比起来, 它不是拦截器来缓存请求
* 转发到别的服务器: 这种设计更加罕见, 也就是限流的请求, 可以被转发过去别的机器上, 但是对于微服务框架来说, 这意味着在服务端也要类似于客户端
    那样发现服务实例, 并且判定服务实例的性能. 一种简化设计就是结合前面的failover, 返回一个类似于302重定向的错误, 让客户端重新发请求到别的节点

熔断、限流、降级有什么区别
如果判断到资源不足, 那么只允许一部分请求被正常处理, 那么就是限流.
对于那些没有被正常处理的请求来说: 如果请求被直接拒绝, 返回错误, 那么这部分请求就被熔断了. 如果请求没有被拒绝, 但是返回了默认值, 或者走了简易路径, 那么就是降级了

## 可观测性

代码演示 micro_v5
v0: micro_v4的v2版本代码
v0: metrics代码演示